# LLMxRobot

This repository is a two in one codebase for two papers on using Large Language Models (LLMs) for autonomous driving on a small-scale robotic platform.


In our [RSS 2025 paper](https://arxiv.org/abs/2504.11514), **Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models**. We demonstrate how LLMs can be used for autonomous driving. It provides the codebase for the **MPCxLLM** and **DecisionxLLM** modules, alongside tools for training, testing, and deployment.

üöó Small LLMs can adapt driving behavior through MPC and perform decision making:

<p align="center"\>
  <img src=".misc/rss_abstract_figure.png" width="600" alt="RobotxLLM Overview"\>
</p\>

Watch an explanatory Youtube video accompanying the paper [here](https://www.youtube.com/watch?v=4iGN1uBl4v4).

In our [CoRL 2025 paper](https://arxiv.org/abs/2505.03238), **RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning**. We build uppon the previous robotic system and introduce closed-loop RL training of LLMs to to foster a *learning by doing* paradigm for embodied robotic intelligence. Showing that small scale LLMs can learn to drive a robot car through RL from its own experience.

üìà +20.2%-points improvement over SFT baseline with Qwen2.5-1.5B via RL.

üß† 63.3% control adaptability with Qwen2.5-3B, surpassing GPT-4o (58.5%) in this robotic task:

<p align="center"\>
  <img src=".misc/corl_abstract_figure.png" width="600" alt="RobotxLLM Overview"\>
</p\>

üìä Check out the Wandb report of the training runs [here](https://wandb.ai/CoRL-heist-2025/mpc_grpo/reports/RobotxR1-Training-Runs--VmlldzoxNDEwOTczNQ?accessToken=a2qws19tg5fuwv7bi2mto42lbjj9l83hyz3feib3vj6x6dp25ul8j6wqhvkiuhcq).

üìπ The Youtube video accompanying the paper can be found [here](https://youtu.be/6mqb9w9n1zs).

## üöÄ Installation

### CUDA Platform (e.g., RTX 30xx / 40xx)

1. Build the Docker container (adapt `CUDA_ARCH` accordingly: `75` for RTX20xx, `86` for RTX 30xx, `89` for 40xx):
   ```bash
   docker build --build-arg CUDA_ARCH=<your_compute_capability> -t embodiedai -f .docker_utils/Dockerfile.cuda .
   ```

2. Mount the container to the project directory:
   ```bash
   ./.docker_utils/main_dock.sh cuda
   ```

3. Attach to the container:
   ```bash
   docker exec -it embodiedai_dock /bin/bash
   ```
   or use VS Code Remote Containers.

---

### Jetson Platform (e.g., Orin AGX)

1. Build the ARM-compatible Docker image:
   ```bash
   docker build -t embodiedai -f .docker_utils/Dockerfile.jetson .
   ```
   **Note that on the jetson, unsloth can not be installed (as of 07.05.2025). So only inference via quantized models are possible!**

2. Mount and launch the container:
   ```bash
   ./.docker_utils/main_dock.sh jetson
   ```

3. Attach via terminal or VS Code.

---

## üîã Jetson power profiling (tegrastats)

Jetson does not provide true per-process (per-PID) power attribution. The most practical approach is to log the relevant power rails with `tegrastats` while your workload runs, then optionally subtract an idle baseline to estimate the workload‚Äôs incremental energy.

From the **host** (Jetson), with the container already running:
```bash
cd /path/to/RISCVxLLMxRobot
./scripts/profile_jetson_power.sh --container embodiedai_dock --baseline-s 10 --interval-ms 200
```

This writes logs to `src/LLMxRobot/logs/power_profiles/` and prints energy summaries for `VIN_SYS_5V0`, `VDD_GPU_SOC`, and `VDD_CPU_CV`.

If your container mounts `src/LLMxRobot` directly at `/embodiedai` (the default in `.docker_utils/main_dock.sh`), the script auto-detects the correct workdir; otherwise pass `--workdir <path-in-container>`.

Stop the profiling at any time with `Ctrl-C` (it terminates the container workload and stops `tegrastats`).

### LLM-only energy (exclude prompt/RAG/metrics)

The most robust way to estimate ‚ÄúLLM-only energy‚Äù is to **separate prompt construction from inference**:
1) Export the prompts you care about (this can include RAG/prompt templating, but runs no LLM).
2) Run a decode-only benchmark that only does GGUF inference on those prompts, while profiling power.

Export prompts (inside the container):
```bash
python3 -m tests.decision_tester.export_prompts \
  --model models/microsoft_Phi-3-mini-4k-instruct-gguf \
  --dataset centerline --mini \
  --out data/prompts_centerline_mini.jsonl
```

Decode-only benchmark (inside the container):
```bash
python3 -m inference.gguf_decode_bench \
  --model_dir models/microsoft_Phi-3-mini-4k-instruct-gguf \
  --prompts data/prompts_centerline_mini.jsonl \
  --limit 50 --hard-exit
```

Then wrap the decode-only benchmark with the host profiler:
```bash
cd /path/to/RISCVxLLMxRobot
./scripts/profile_jetson_power.sh --container embodiedai_dock --baseline-s 30 --interval-ms 100 --segment-llm \
  --cmd "python3 -m inference.gguf_decode_bench --model_dir models/microsoft_Phi-3-mini-4k-instruct-gguf --prompts data/prompts_centerline_mini.jsonl --limit 50 --hard-exit"
```

This prints an extra ‚ÄúLLM-only segment summary‚Äù and writes per-call energies to `src/LLMxRobot/logs/power_profiles/llm_segments_*.csv`.

If `Ctrl-C` still feels ‚Äústuck‚Äù, the profiler now force-kills lingering `docker exec`/`tegrastats` processes after a short timeout (tunable via `--kill-timeout-s`).

On some Jetson builds, `llama-cpp-python` can abort or hang during Python interpreter shutdown (after the script ‚Äúfinishes‚Äù). In `--segment-llm` mode the profiler automatically sets `LLMXROBOT_HARD_EXIT=1` to avoid that; you can disable it by passing `--env LLMXROBOT_HARD_EXIT=0`.

To re-analyze logs after the fact:
- Whole-run rail summary: `python3 scripts/summarize_tegrastats.py --tegrastats-log src/LLMxRobot/logs/power_profiles/tegrastats_<timestamp>.log --interval-ms <ms> --baseline-samples <N> --rails VIN_SYS_5V0,VDD_GPU_SOC,VDD_CPU_CV`
- LLM-only per-call CSV: `python3 scripts/summarize_tegrastats_segments.py --tegrastats-log src/LLMxRobot/logs/power_profiles/tegrastats_<timestamp>.log --run-log src/LLMxRobot/logs/power_profiles/workload_<timestamp>.log --interval-ms <ms> --baseline-samples <N> --rails VIN_SYS_5V0,VDD_GPU_SOC,VDD_CPU_CV --out-csv out.csv`

To do a quick sanity run (instead of hours-long `--dataset all`), run a smaller evaluation:
- Prefer `--mini` (subsampled) and/or a single `--dataset <name>` in `tests.decision_tester.decision_tester`.
- You can also pass a shorter command to the profiler via `--cmd`, e.g. `--cmd "python3 -m tests.decision_tester.decision_tester --model models/microsoft_Phi-3-mini-4k-instruct-gguf --dataset centerline --quant --mini"`.

### Create .env File
Create a `.env` file in the root directory with the following content:
```bash
HUGGINGFACEHUB_API_TOKEN="<your_huggingface_token>"
OPENAI_API_TOKEN="<your_openai_token>"
WANDB_API_KEY="<your_wandb_api_key>" # Optional
```
This is needed for downloading models and using OpenAI APIs which is required if you want to use `gpt-4o` or for using the modules with their RAG embeddings. **Make sure to keep this file private!**

### Download Pre-Trained Models (optional)
**Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models**:

You can use the LoRA + RAG SFT trained FP16 model [nibauman/RobotxLLM_Qwen7B_SFT](https://huggingface.co/nibauman/RobotxLLM_Qwen7B_SFT) directly from HuggingFace 
without having to download it locally. If you want to use the quantized model, you can download it with the following command:

```bash
huggingface-cli download nibauman/race_llm-Q5_K_M-GGUF --local-dir models/race_llm_q5
```
**RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning**:

The SFT and GRPO trained models for DecisionxLLM and MPCxLLM are available on HuggingFace:
- DecisionxLLM Qwen-1.5B: [nibauman/DecisionxR1_Qwen1.5B_SFT_GRPO](https://huggingface.co/nibauman/DecisionxR1_Qwen1.5B_SFT_GRPO)
- DecisionxLLM Qwen-3B: [nibauman/DecisionxR1_Qwen3B_SFT_GRPO](https://huggingface.co/nibauman/DecisionxR1_Qwen3B_SFT_GRPO)
- MPCxLLM Qwen-1.5B: [nibauman/MPCxR1_Qwen1.5B_SFT_GRPO](https://huggingface.co/nibauman/MPCxR1_Qwen1.5B_SFT_GRPO)
- MPCxLLM Qwen-3B: [nibauman/MPCxR1_Qwen3B_SFT_GRPO](https://huggingface.co/nibauman/MPCxR1_Qwen3B_SFT_GRPO)
---

## üß† Usage

This repo integrates with the [ForzaETH Race Stack](https://github.com/ForzaETH/race_stack). Follow their installation instructions and ensure your `ROS_MASTER_URI` is correctly configured (see [example line](https://github.com/ForzaETH/race_stack/blob/main/.devcontainer/.install_utils/bashrc_ext#L12)) in this readme we use 192.168.192.75 as an example!

### On the Robot Stack
Run each command in a separate terminal. Use `f` map for evaluation and `circle` map (`map_name:=circle`) for RobotxR1 RL training.
```bash
roscore
roslaunch stack_master base_system.launch map_name:=f racecar_version:=NUC2 sim:=true
roslaunch stack_master time_trials.launch ctrl_algo:=KMPC
roslaunch rosbridge_server rosbridge_websocket.launch address:=192.168.192.75
```

### On the LLM Machine

```bash
python3 llm_mpc.py --model custom --model_dir nibauman/RobotxLLM_Qwen7B_SFT --hostip 192.168.192.75 --prompt "Drive in Reverse!"
```

**Key Options:**

- `--model`: `custom` or `gpt-4o`
- `--model_dir`: HuggingFace or local path (used for `custom`)
- `--hostip`: ROS master IP
- `--prompt`: Natural language instruction
- `--quant`: Use quantized `GGUF` model
- `--mpconly`: Skip DecisionxLLM

As an **example** for on the **Jetson** you can only run the quantized models with the models downloaded to the models folder as explained above. You can run the following command to test the quantized model:
```bash
python3 llm_mpc.py --model custom --model_dir models/race_llm_q5 --hostip 192.168.192.75 --prompt "Drive in Reverse!" --quant
```
---

## üèãÔ∏è Training

To train a new LoRA adapter on synthetic data with **Supervised Fine-Tuning (SFT)** akin to *Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models* [here](https://arxiv.org/abs/2504.11514), you can use the following command:

```bash
python3 -m train.sft_train --config train/config/sft_train.yaml
```

You can modify `sft_train.yaml` to change training parameters. Default setup:

- Base Model: `unsloth/Qwen2.5-7B-Instruct`

To train the DecisionxLLM through **static Reinforcement Learning** akin to *RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning* [here](https://arxiv.org/abs/2505.03238), you can use the following command:

```bash
python3 -m train.rl_decision_train --config train/config/rl_decision_train.yaml
```

Modify `rl_decision_train.yaml` to change training parameters. Default setup:
- Base Model: `Qwen/Qwen2.5-3B-Instruct`

To train the MPCxLLM through **feedback driven Reinforcement Learning** akin to *RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning* [here](https://arxiv.org/abs/2505.03238), you can use the following command:

```bash
python3 -m train.rl_mpc_train --config train/config/rl_mpc_train.yaml
```
Modify `rl_mpc_train.yaml` to change training parameters. Default setup:
- Base Model: `Qwen/Qwen2.5-3B-Instruct`

**Note:** Train the model on the `circle`map, then evaluate it on the `f` map. Command to launch the robot stack on the `circle` map:
```bash
roslaunch stack_master base_system.launch map_name:=circle racecar_version:=NUC2 sim:=true
```    
---

## üìä Evaluation

### DecisionxLLM Evaluation (autonomy stack not required)

```bash
python3 -m tests.decision_tester.decision_tester --model nibauman/RobotxLLM_Qwen7B_SFT --dataset all --mini --rag
```

### MPCxLLM Evaluation (requires autonomy stack)

```bash
python3 -m tests.mpc_tester.mpc_tester --model custom --model_dir nibauman/RobotxLLM_Qwen7B_SFT --host_ip 192.168.192.75
```

**Evaluation Options:**

- `--dataset`: e.g., `all`, `stop`, `reverse`, etc.
- `--mini`: Run a small evaluation subset
- `--rag`: Enable retrieval-augmented decision prompts
- `--quant`: Use quantized model
---
## Acknowledgements
SFT training was performed through the distillation of [OpenAI GPT-4o](https://openai.com/index/hello-gpt-4o/) queries.
This work would not have been possible without the great work of other repositories such as:
- [llama.cpp](https://github.com/ggml-org/llama.cpp)
- [Hugging Face](https://github.com/huggingface)
- [unsloth](https://github.com/unslothai/unsloth)
- [roslibpy](https://github.com/gramaziokohler/roslibpy)
---

## üìÑ Citation

If this repository is useful for your research, please consider citing our work:

**Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models:**
```bibtex
@article{baumann2025enhancing,
  title={Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models},
  author={Baumann, Nicolas and Hu, Cheng and Sivasothilingam, Paviththiren and Qin, Haotong and Xie, Lei and Magno, Michele and Benini, Luca},
  journal={arXiv preprint arXiv:2504.11514},
  year={2025}
}
```
**RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning:**
```bibtex
@misc{boyle2025robotxr1enablingembodiedrobotic,
      title={RobotxR1: Enabling Embodied Robotic Intelligence on Large Language Models through Closed-Loop Reinforcement Learning}, 
      author={Liam Boyle and Nicolas Baumann and Paviththiren Sivasothilingam and Michele Magno and Luca Benini},
      year={2025},
      eprint={2505.03238},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2505.03238}, 
}
```
